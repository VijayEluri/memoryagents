\chapter{Simulation and Used Memory Architectures}

In this chapter we will describe the simulation, environment and agent's reasoning and communication how it is used in later experiments. 

\section{Simulation}

The \emph{simulation} consists of a set of agents, a set of generators and a set of pieces of food. According to given settings it subsequently processes a number of steps, each of which invokes agents' life step and eventually generating new food. There are six kinds of food, each of which has its food generator at given position in the environment. The food generator regurarly drops new piece of food randomly using Gaussian distribution around the generator's position. An agent task is to search for the food, as he is getting more hungry every step of the simulation. There is a separate need for each food, i.e. the agent has to find all six food resources. 

Each agent is able to percieve the environment, but they had limited perception restricted by their sight, except for the pure reactive agent which sees all the enviroment. Agents also can communicate with each others and there two kinds of agents which has a spatial memory - GNG agent and grid agent.

The simulation can also contain a couple of monitors which observe the environment or agents. Their purpose is to write the current state of the simulation into the file so as to be able to create graphs and compute statistical values. Other kind of environment observer is the visualiser, which allows us to see what each agent sees and believes.

\section{Environment}

The environment is a two-dimensional space which contains agents and food. Agents can move around and eat the food which is randomly distributed using the food generators. 

\section{Agent}                                                      
As mentioned previously, an agent is an entity in the environment which moves and interact with the world around. The interaction is done through eating food which is a part of the environment and through communication with other agents. The latter one actually changes agents' beliefs about the environment. He moves discretely each step of simulation. There is an order in which the agents are sequently processed; we did not want to handicap anyone, so we tried to emulate parallel processing by spliting agents' step phases into groups such as percieving the environment, actions and dying.

Each agent has his needs which influence his decisions as fulfilling his needs keeps him alive. When his internal variables of needs is higher than a treshold he starts searching for the appropriate food resource. He uses his sight which allows him to percieve the space around him in the set distance. If he does not see anything and is allowed to communicate, he can ask the agents around him, but again only in the distance of audition.

There are four types of agents each of which is different in the way they decide about next step. If one is hungry and sees food (i.e. there is a piece of food in the sight distance) then they choose to go after this food. If there is no desired food around they go searching for it and that is when the agents' actions differ.

\begin{itemize}
\item \emph{random agent} moves randomly around the environment,
\item \emph{pure reactive agent} sees the whole environment, i.e. they always sees a desired piece of food, 
\item \emph{grid agent} implements a memory based on clustering the space into a grid,
\item \emph{GNG agent} implements a memory based on growing neural gas.
\end{itemize}

\section{Communication}

Apart from what agent sees, there is another way how the agents gather information about the environment. They communicate. It is a quite simple way of sharing information. When suggesting an implementation for communication, I had to create a unified protocol which could have been used throughout all types of agents. I tried to keep this communication protocol as simple as possible.

Moreover, although all agents have a knowledge of a sort about the environment, they are not able to answer easily when asked about a specific food location. Since the food appears in environment according to given normal distribution, it is not clear what should be an answer to such question. Several possible kinds of answers follow. 

First and the simplest answer might be the exact X,Y coordinates of the food location as it is stored in agent's mind. Additionally, there would be a noise added to such answer, keeping in mind that the answer should not be perfect and there is always a distortion and imperfection in our answers based on how a person is certain about his answer.
                                              
Another way, and perhaps a more plausible one, might be answering with a direction (an angle) with an approximate distance. What both the X, Y answer and the latter information have in common is that the answers are hard to combine with the learning method used in GNG memory. GNG works with samples of data which subsequently influence the neural network. Both kinds of answers could be used if agents would ask more often or the agent's answer would be a sample of points straight away.

So I have implemented a communication model (see \ref{solution:decision}) whereby an answer consists of a small set of points. Each point is generated according to agent's knowledge. When an agent is asked, first he uses his either GNG memory, or grid memory to estimate the Gaussian distribution of the food resource and then randomly generates the points using the estimated distribution.

\begin{figure}
  \centering                                
  \includegraphics[scale=0.7]{diagrams/solution/communication.eps}    
  \caption{Simple communication protocol}
  \label{solution:communication}
\end{figure}

\section{Decision Making}

While searching for food, each type of the agent makes the decision where to go next. This process is either done randomly or following one's knowledge of the environment. A simple diagram of decision making follows.

\begin{figure}
  \centering                                
  \includegraphics[scale=0.5]{diagrams/solution/decision-flowchart.eps}    
  \caption{How the agent decides what to do next}
  \label{solution:decision}
\end{figure}

The diagram \ref{solution:decision} shows how an agents decides what to do. In fact it is common for all types of agents described in this thesis, although the first step "Put known food location into memory" is omitted in case of \emph{random} and \emph{PR agents}. 

First an agent puts into his memory known food locations. These are locations which he either sees, or remembers from the last simulation step. After that he checks his internal variables to see whether he is hungry or not. If he is hungry, he tries to decide where his desired food resource is. He uses his memory, sight and eventually communication with other agents. 

The output of this process is a group of possible locations from which he chooses the closest one and head towards it. If he occures at the position where the desired food also is, he eats it. Throught the decision flow there are two moments, when the agent does not know what to do and then he moves randomly: when he does not need to eat anything and when he cannot find the the path to the food resource.

\section{Memories}

There are two types of memory which should allow agents to improve their lifespan compared to a random agent. Those are memories based on a growing neural gas and a spatial grid.     

\begin{figure}      
\begin{center}
\includegraphics{images/app/grid_screenshot.eps}    
\caption{A visualization of an grid agent's memory and the situation in the environment. The coloured bars on the left side show current levels of agent's hunger. Coloured squares display grid cell values.}
\end{center}                          
\label{app:gridscreenshot}
\end{figure}

The \emph{GNG memory} uses a self-teaching neural network which has been described in \ref{usedalgo:gng}. The neural network allows the agent to learn the approximate location where the food is distributed. Each kind of food is given a single neural network which tries to learn the distribution reflecting the data inputs.

\begin{figure}      
\begin{center}
\includegraphics{images/app/gng_screenshot.eps}    
\caption{A visualization of an GNG agent's memory and the situation in the environment. Connected coloured circles represent growing neural gas for each food kind.}
\end{center}                          
\label{app:gngscreenshot}
\end{figure}

The \emph{grid memory} divides the environment into a grid in order to simplify the space and to restrict the total size of the data structure used to describe the space. There are 16 cells, each of which has six \emph{positive/negative} pairs of variables as there are six kinds of food. When an agent moves around the environment and sees the food the \emph{positive} value of an appropriate cell is increased, it is the same when an agent recieve information about the food position. On the other hand, when an agent reaches the cell and sees there is no food, the \emph{negative} value is increased.